{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "dataset_size = [\"small\", \"medium\", \"large\"][1]\n",
    "\n",
    "dataset_info = {\n",
    "    \"small\": {\n",
    "        \"dataset_name\": \"wine\",\n",
    "        \"class_name\": \"Class\",\n",
    "        \"drop_fields\": []\n",
    "    },\n",
    "    \"medium\": {\n",
    "        \"dataset_name\": \"breast-cancer-wisconsin\",\n",
    "        \"class_name\": \"Class\",\n",
    "        \"drop_fields\": [\"Sample code number\"]\n",
    "    },\n",
    "    \"large\": {\n",
    "        \"dataset_name\": \"seismic-bumps\",\n",
    "        \"class_name\": \"class\",\n",
    "        \"drop_fields\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset_name = dataset_info[dataset_size][\"dataset_name\"]\n",
    "class_name = dataset_info[dataset_size][\"class_name\"]\n",
    "drop_fields = dataset_info[dataset_size][\"drop_fields\"]\n",
    "\n",
    "df = pd.read_csv('../data/' + dataset_name + \".csv\")\n",
    "df = df.drop(drop_fields, axis=1)\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "\n",
    "n_cut = int(0.8*len(df))\n",
    "df_trn = df[:n_cut]\n",
    "df_tst = df[n_cut:]\n",
    "\n",
    "X_trn = df_trn.drop(class_name, axis=1)\n",
    "y_trn = df_trn[class_name]\n",
    "\n",
    "X_tst = df_tst.drop(class_name, axis=1)\n",
    "y_tst = df_tst[class_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"breast-cancer-wisconsin\":\n",
    "    aux_col = X_trn[\"Bare Nuclei\"]\n",
    "    values, counts = np.unique(aux_col[aux_col != \"?\"].astype(int), return_counts=True)\n",
    "    \n",
    "    most_frequent_value = values[np.argmax(counts)]\n",
    "    aux_col = aux_col.replace({\"?\": str(most_frequent_value)})\n",
    "        \n",
    "    X_trn[\"Bare Nuclei\"] = aux_col.to_numpy().astype(int)\n",
    "    \n",
    "    X_tst[\"Bare Nuclei\"] = X_tst[\"Bare Nuclei\"].replace({\"?\": str(most_frequent_value)})\n",
    "    X_tst[\"Bare Nuclei\"] = X_tst[\"Bare Nuclei\"].astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Dataset breast-cancer-wisconsin:\n",
      "------------------------------\n",
      "\n",
      "NaN values (Train):\n",
      "------------------------------\n",
      "Column Clump Thickness has 0 NaN values\n",
      "Column Uniformity of Cell Size has 0 NaN values\n",
      "Column Uniformity of Cell Shape has 0 NaN values\n",
      "Column Marginal Adhesion has 0 NaN values\n",
      "Column Single Epithelial Cell Size has 0 NaN values\n",
      "Column Bare Nuclei has 0 NaN values\n",
      "Column Bland Chromatin has 0 NaN values\n",
      "Column Normal Nucleoli has 0 NaN values\n",
      "Column Mitoses has 0 NaN values\n",
      "\n",
      "NaN values (Test):\n",
      "------------------------------\n",
      "Column Clump Thickness has 0 NaN values\n",
      "Column Uniformity of Cell Size has 0 NaN values\n",
      "Column Uniformity of Cell Shape has 0 NaN values\n",
      "Column Marginal Adhesion has 0 NaN values\n",
      "Column Single Epithelial Cell Size has 0 NaN values\n",
      "Column Bare Nuclei has 0 NaN values\n",
      "Column Bland Chromatin has 0 NaN values\n",
      "Column Normal Nucleoli has 0 NaN values\n",
      "Column Mitoses has 0 NaN values\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*30)\n",
    "print(f'Dataset {dataset_name}:')\n",
    "print(\"-\"*30)\n",
    "print()\n",
    "\n",
    "print(\"NaN values (Train):\")\n",
    "print(\"-\"*30)\n",
    "for col in X_trn.columns:\n",
    "    if X_trn.dtypes[col] == int or X_trn.dtypes[col] == float:\n",
    "        print(f'Column {col} has {np.isnan(X_trn[col]).sum()} NaN values')\n",
    "    else:\n",
    "        print(f'Column {col} has unique values {X_trn[col].unique()}')\n",
    "        \n",
    "print()\n",
    "print(\"NaN values (Test):\")\n",
    "print(\"-\"*30)\n",
    "for col in X_tst.columns:\n",
    "    if X_tst.dtypes[col] == int or X_tst.dtypes[col] == float:\n",
    "        print(f'Column {col} has {np.isnan(X_tst[col]).sum()} NaN values')\n",
    "    else:\n",
    "        print(f'Column {col} has unique values {X_tst[col].unique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_df(X_trn, X_tst, n_bins=3):\n",
    "    \n",
    "    cols_to_discretize = [col for col in X_trn.columns if X_trn[col].dtype == float or X_trn[col].dtype == int]\n",
    "    \n",
    "    if len(cols_to_discretize) == 0:\n",
    "        return X_trn, X_tst\n",
    "    \n",
    "    est = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "    \n",
    "    X_trn_aux = X_trn[cols_to_discretize].to_numpy()\n",
    "    X_tst_aux = X_tst[cols_to_discretize].to_numpy()\n",
    "    \n",
    "    if len(X_trn_aux.shape) > 1:\n",
    "        X_trn_aux = est.fit_transform(X_trn_aux)\n",
    "        X_tst_aux = est.transform(X_tst_aux)\n",
    "        \n",
    "    else:    \n",
    "        X_trn_aux = X_trn_aux[:, None]\n",
    "        X_tst_aux = X_tst_aux[:, None]\n",
    "        \n",
    "        X_trn_aux = est.fit_transform(X_trn_aux)\n",
    "        X_tst_aux = est.transform(X_tst_aux)\n",
    "\n",
    "\n",
    "        X_trn_aux = X_trn_aux.reshape(X_trn_aux.shape[0])\n",
    "        X_tst_aux = X_tst_aux.reshape(X_tst_aux.shape[0])\n",
    "    \n",
    "    X_trn_aux = X_trn_aux.astype(int).astype(str)\n",
    "    X_tst_aux = X_tst_aux.astype(int).astype(str)\n",
    "    \n",
    "    X_trn[cols_to_discretize] = X_trn_aux\n",
    "    X_tst[cols_to_discretize] = X_tst_aux\n",
    "        \n",
    "    dict_replace = {\n",
    "        3: {'0': 'L', '1': 'M', '2': 'H'},\n",
    "        5: {'0': 'LL', '1': 'L', '2': 'M', '3': 'H', '4': 'HH'}\n",
    "    }\n",
    "    \n",
    "    X_trn = X_trn.replace(dict_replace[n_bins])\n",
    "    X_tst = X_tst.replace(dict_replace[n_bins])\n",
    "\n",
    "    return X_trn, X_tst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, X_tst = discretize_df(X_trn, X_tst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_delta_over_alpha(X, y, values_x, value_y):\n",
    "    \n",
    "    cond_x = np.ones(len(X), dtype=bool)\n",
    "    for key, value in values_x.items():\n",
    "        cond_x *= (X[key] == value).to_numpy()\n",
    "\n",
    "    cond_x_and_y = (y == value_y).to_numpy() * cond_x\n",
    "    \n",
    "    count_alpha_x = cond_x.sum()\n",
    "    count_delta_n_and_alpha_x = cond_x_and_y.sum()\n",
    "    \n",
    "    if count_alpha_x > 0:\n",
    "        return count_delta_n_and_alpha_x / count_alpha_x, count_delta_n_and_alpha_x\n",
    "    \n",
    "    return np.nan, 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dfs(X, y, rule, keep=True):\n",
    "    cond_x = np.ones(len(X), dtype=bool)\n",
    "    for key, value in rule.items():\n",
    "        cond_x *= (X[key] == value).to_numpy()\n",
    "        \n",
    "    if not keep:\n",
    "        cond_x = np.array(1 - cond_x, dtype=bool)\n",
    "    \n",
    "    X = X[cond_x]\n",
    "    y = y[cond_x]\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rules(X_trn, y_trn, set_attribute_values, class_unique_values):\n",
    "    all_Rs = []\n",
    "\n",
    "    for class_value in class_unique_values:\n",
    "        print(f'Fitting class value {class_value}')\n",
    "        \n",
    "        all_Rs_class = []\n",
    "        still_instances_delta_n = True\n",
    "        \n",
    "        X_remaining, y_remaining = X_trn.copy(), y_trn.copy()\n",
    "        X_rule, y_rule = X_trn.copy(), y_trn.copy()\n",
    "        while still_instances_delta_n:\n",
    "            \n",
    "            number_of_attributes_of_rule = 0\n",
    "            creating_rule = True\n",
    "            X_rule, y_rule = X_remaining.copy(), y_remaining.copy()\n",
    "            Rule = {}\n",
    "            set_attributes_not_used = set_attribute_values.copy()\n",
    "            \n",
    "            while creating_rule:\n",
    "                all_ps = []\n",
    "                for (attribute_name, attribute_value) in set_attributes_not_used:\n",
    "                    values_x = {attribute_name: attribute_value}\n",
    "                    p_delta_alpha, n_delta_alpha = compute_p_delta_over_alpha(X_rule, y_rule, values_x, class_value)\n",
    "                    all_ps.append((attribute_name, attribute_value, (p_delta_alpha, n_delta_alpha)))\n",
    "\n",
    "                all_ps = [elem for elem in all_ps if not np.isnan(elem[-1][0])]\n",
    "                all_ps.sort(key=lambda tup: tup[-1])\n",
    "                \n",
    "                if len(all_ps):\n",
    "                    rule_attribute_name, rule_attribute_value, (rule_p, rule_n) = all_ps[-1]\n",
    "                    number_of_attributes_of_rule += 1\n",
    "                    \n",
    "                    Rule[rule_attribute_name] = rule_attribute_value\n",
    "                    set_attributes_not_used.remove((rule_attribute_name, rule_attribute_value))\n",
    "                    \n",
    "                    X_rule, y_rule = filter_dfs(X_rule, y_rule, {rule_attribute_name: rule_attribute_value}, keep=True)\n",
    "\n",
    "                    n_rule = (y_rule == class_value).to_numpy().sum()\n",
    "                    c_rule = len(y_rule)\n",
    "                    if n_rule == c_rule:\n",
    "                        creating_rule = False\n",
    "                        \n",
    "                        p_rule = n_rule / c_rule\n",
    "                        \n",
    "                        all_Rs_class.append((Rule, class_value, p_rule, c_rule))\n",
    "                        \n",
    "                        X_remaining, y_remaining = filter_dfs(X_remaining, y_remaining, Rule, keep=False)\n",
    "                \n",
    "                elif number_of_attributes_of_rule == len(X_trn.columns):\n",
    "                    creating_rule = False\n",
    "                    \n",
    "                    n_rule = (y_rule == class_value).to_numpy().sum()\n",
    "                    c_rule = len(y_rule)\n",
    "                    p_rule = n_rule / c_rule\n",
    "                    \n",
    "                    all_Rs_class.append((Rule, class_value, p_rule, c_rule))\n",
    "                    \n",
    "                    X_remaining, y_remaining = filter_dfs(X_remaining, y_remaining, Rule, keep=False)\n",
    "                \n",
    "            cond_y = (y_remaining == class_value).to_numpy()\n",
    "            if cond_y.sum() == 0:\n",
    "                for rule in all_Rs_class:\n",
    "                    all_Rs.append(rule)\n",
    "\n",
    "                still_instances_delta_n = False\n",
    "    \n",
    "    return all_Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting class value 4\n",
      "Fitting class value 2\n"
     ]
    }
   ],
   "source": [
    "attributes_unique_values = {col_name: X_trn[col_name].unique() for col_name in X_trn.columns if col_name != class_name}\n",
    "class_unique_values = y_trn.unique()\n",
    "\n",
    "set_attribute_values = set([(attribute_name, attribute_value) for attribute_name in attributes_unique_values for attribute_value in attributes_unique_values[attribute_name]])\n",
    "\n",
    "all_Rs = fit_rules(X_trn, y_trn, set_attribute_values, class_unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1: Clump Thickness = L && Bare Nuclei = L && Marginal Adhesion = L --> 2 (n = 223, p = 100.0%)\n",
      "R2: Clump Thickness = M && Uniformity of Cell Shape = L && Marginal Adhesion = L && Uniformity of Cell Size = L && Bland Chromatin = L && Single Epithelial Cell Size = L && Normal Nucleoli = L && Mitoses = L && Bare Nuclei = L --> 4 (n = 107, p = 0.9%)\n",
      "R3: Uniformity of Cell Shape = L && Bare Nuclei = L && Bland Chromatin = L && Single Epithelial Cell Size = L && Marginal Adhesion = L && Mitoses = L && Clump Thickness = M && Uniformity of Cell Size = L && Normal Nucleoli = L --> 2 (n = 107, p = 99.1%)\n",
      "R4: Uniformity of Cell Shape = H && Bland Chromatin = H --> 4 (n = 59, p = 100.0%)\n",
      "R5: Marginal Adhesion = H && Bare Nuclei = H --> 4 (n = 25, p = 100.0%)\n",
      "R6: Uniformity of Cell Size = H && Clump Thickness = H --> 4 (n = 19, p = 100.0%)\n",
      "R7: Mitoses = M --> 4 (n = 17, p = 100.0%)\n",
      "R8: Bare Nuclei = H && Bland Chromatin = M --> 4 (n = 16, p = 100.0%)\n",
      "R9: Clump Thickness = H && Bare Nuclei = M --> 4 (n = 9, p = 100.0%)\n",
      "R10: Bare Nuclei = H && Clump Thickness = H && Marginal Adhesion = L --> 4 (n = 9, p = 100.0%)\n",
      "R11: Uniformity of Cell Shape = L && Bland Chromatin = L && Clump Thickness = L --> 2 (n = 8, p = 100.0%)\n",
      "R12: Bare Nuclei = L && Clump Thickness = M && Bland Chromatin = L --> 2 (n = 8, p = 100.0%)\n",
      "R13: Bland Chromatin = H && Normal Nucleoli = M --> 4 (n = 4, p = 100.0%)\n",
      "R14: Bare Nuclei = H && Bland Chromatin = H && Normal Nucleoli = L --> 4 (n = 4, p = 100.0%)\n",
      "R15: Clump Thickness = H && Normal Nucleoli = M --> 4 (n = 3, p = 100.0%)\n",
      "R16: Bland Chromatin = H && Single Epithelial Cell Size = H --> 4 (n = 3, p = 100.0%)\n",
      "R17: Bare Nuclei = H && Single Epithelial Cell Size = L && Uniformity of Cell Size = M --> 4 (n = 3, p = 100.0%)\n",
      "R18: Uniformity of Cell Shape = L && Bare Nuclei = L && Marginal Adhesion = M --> 2 (n = 3, p = 100.0%)\n",
      "R19: Uniformity of Cell Shape = L && Bare Nuclei = L && Bland Chromatin = L && Clump Thickness = H --> 2 (n = 3, p = 100.0%)\n",
      "R20: Normal Nucleoli = H && Uniformity of Cell Size = L --> 4 (n = 2, p = 100.0%)\n",
      "R21: Mitoses = H && Clump Thickness = H --> 4 (n = 2, p = 100.0%)\n",
      "R22: Uniformity of Cell Size = H && Single Epithelial Cell Size = H --> 4 (n = 2, p = 100.0%)\n",
      "R23: Clump Thickness = H && Bland Chromatin = H && Marginal Adhesion = L --> 4 (n = 2, p = 100.0%)\n",
      "R24: Marginal Adhesion = H && Normal Nucleoli = H && Uniformity of Cell Size = M && Mitoses = L && Bland Chromatin = H && Clump Thickness = M && Bare Nuclei = L && Single Epithelial Cell Size = M && Uniformity of Cell Shape = M --> 4 (n = 2, p = 50.0%)\n",
      "R25: Bare Nuclei = H && Uniformity of Cell Shape = L && Clump Thickness = M && Single Epithelial Cell Size = L && Mitoses = L && Normal Nucleoli = M && Uniformity of Cell Size = L && Marginal Adhesion = M && Bland Chromatin = L --> 4 (n = 2, p = 50.0%)\n",
      "R26: Uniformity of Cell Shape = L && Bland Chromatin = L && Uniformity of Cell Size = M --> 2 (n = 2, p = 100.0%)\n",
      "R27: Uniformity of Cell Shape = L && Clump Thickness = L && Single Epithelial Cell Size = L --> 2 (n = 2, p = 100.0%)\n",
      "R28: Bland Chromatin = L && Clump Thickness = M && Uniformity of Cell Size = H --> 2 (n = 2, p = 100.0%)\n",
      "R29: Bare Nuclei = L && Clump Thickness = M && Normal Nucleoli = L && Uniformity of Cell Shape = L --> 2 (n = 2, p = 100.0%)\n",
      "R30: Bare Nuclei = L && Uniformity of Cell Size = M && Normal Nucleoli = H && Mitoses = L && Bland Chromatin = H && Clump Thickness = M && Marginal Adhesion = H && Single Epithelial Cell Size = M && Uniformity of Cell Shape = M --> 2 (n = 2, p = 50.0%)\n",
      "R31: Marginal Adhesion = M && Uniformity of Cell Shape = L && Bland Chromatin = L && Single Epithelial Cell Size = L && Bare Nuclei = H && Mitoses = L && Clump Thickness = M && Normal Nucleoli = M && Uniformity of Cell Size = L --> 2 (n = 2, p = 50.0%)\n",
      "R32: Bare Nuclei = H && Mitoses = H --> 4 (n = 1, p = 100.0%)\n",
      "R33: Marginal Adhesion = H && Single Epithelial Cell Size = L --> 4 (n = 1, p = 100.0%)\n",
      "R34: Normal Nucleoli = M && Bare Nuclei = M --> 4 (n = 1, p = 100.0%)\n",
      "R35: Bare Nuclei = H && Uniformity of Cell Shape = L && Single Epithelial Cell Size = M --> 4 (n = 1, p = 100.0%)\n",
      "R36: Bland Chromatin = M && Single Epithelial Cell Size = M --> 4 (n = 1, p = 100.0%)\n",
      "R37: Normal Nucleoli = M && Bland Chromatin = M && Uniformity of Cell Shape = L --> 4 (n = 1, p = 100.0%)\n",
      "R38: Bare Nuclei = M && Clump Thickness = M && Bland Chromatin = M --> 4 (n = 1, p = 100.0%)\n",
      "R39: Bare Nuclei = M && Clump Thickness = M && Marginal Adhesion = L && Uniformity of Cell Size = L --> 4 (n = 1, p = 100.0%)\n",
      "R40: Uniformity of Cell Shape = L && Bland Chromatin = L && Marginal Adhesion = H --> 2 (n = 1, p = 100.0%)\n",
      "R41: Uniformity of Cell Shape = L && Bare Nuclei = L && Bland Chromatin = L && Normal Nucleoli = M --> 2 (n = 1, p = 100.0%)\n",
      "R42: Uniformity of Cell Shape = L && Bare Nuclei = L && Bland Chromatin = L && Single Epithelial Cell Size = M --> 2 (n = 1, p = 100.0%)\n",
      "R43: Bare Nuclei = L && Clump Thickness = M && Uniformity of Cell Size = M && Single Epithelial Cell Size = H --> 2 (n = 1, p = 100.0%)\n",
      "R44: Uniformity of Cell Shape = L && Marginal Adhesion = M && Bare Nuclei = M --> 2 (n = 1, p = 100.0%)\n",
      "R45: Bland Chromatin = L && Clump Thickness = M && Marginal Adhesion = M && Single Epithelial Cell Size = H --> 2 (n = 1, p = 100.0%)\n",
      "R46: Bare Nuclei = L && Uniformity of Cell Size = M && Marginal Adhesion = L && Uniformity of Cell Shape = M && Bland Chromatin = M --> 2 (n = 1, p = 100.0%)\n",
      "R47: Marginal Adhesion = M && Uniformity of Cell Size = M && Normal Nucleoli = H && Uniformity of Cell Shape = M && Clump Thickness = H --> 2 (n = 1, p = 100.0%)\n"
     ]
    }
   ],
   "source": [
    "latex_mode = False\n",
    "\n",
    "if latex_mode:\n",
    "    print(\"\\\\begin{itemize}\")\n",
    "    for ind, rule in enumerate(sorted(all_Rs, key=lambda tup: tup[-1], reverse=True)):\n",
    "        s = f'R{ind + 1}: '\n",
    "        rule_attribute_value, class_value, p_rule, c_rule = rule\n",
    "        for attribute_name, attribute_value in rule_attribute_value.items():\n",
    "            s += \"\\\\textbf{\" + attribute_name + \"} = \" + attribute_value + \" $\\\\wedge$ \"\n",
    "        s = s[:-10] + \" $\\\\rightarrow \\delta_\" + str(class_value) + \"$ (n = \" + str(c_rule) + \", p = \" + str(round(100 * p_rule, 1)) + \"\\%)\"\n",
    "        print(\"\\t\\\\item\", s)\n",
    "    print(\"\\\\end{itemize}\")\n",
    "\n",
    "else:\n",
    "    for ind, rule in enumerate(sorted(all_Rs, key=lambda tup: tup[-1], reverse=True)):\n",
    "        s = f'R{ind + 1}: '\n",
    "        rule_attribute_value, class_value, p_rule, c_rule = rule\n",
    "        for attribute_name, attribute_value in rule_attribute_value.items():\n",
    "            s += attribute_name + \" = \" + attribute_value + \" && \"\n",
    "        s = s[:-4] + \" --> \" + str(class_value) + \" (n = \" + str(c_rule) + \", p = \" + str(round(100 * p_rule, 1)) + \"%)\"\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, rules, y_trn, dtype=str):\n",
    "    predictions = pd.Series(np.zeros(len(X)), index=X.index, dtype=dtype)\n",
    "    predictions[:] = np.nan\n",
    "    \n",
    "    for ind, row in X.iterrows():\n",
    "        valid_rules = []\n",
    "        for rule in rules:\n",
    "            rule_attribute_value, class_value, _, c_rule = rule\n",
    "            this_rule = True\n",
    "            for attribute_name, attribute_value in rule_attribute_value.items():\n",
    "                if row[attribute_name] != attribute_value:\n",
    "                    this_rule = False\n",
    "                \n",
    "            if this_rule:\n",
    "                valid_rules.append(rule)\n",
    "                \n",
    "        if len(valid_rules):\n",
    "            max_n = -1\n",
    "            selected_class_value = None\n",
    "            for rule in valid_rules:\n",
    "                _, class_value, _, c_rule = rule\n",
    "                if c_rule > max_n:\n",
    "                    max_n = c_rule\n",
    "                    selected_class_value = class_value\n",
    "            \n",
    "            predictions[ind] = selected_class_value\n",
    "        \n",
    "        elif np.isnan(predictions[ind]):\n",
    "            predictions[ind] = y_trn.mode()\n",
    "    \n",
    "    return predictions    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tst_hat = predict(X_tst, all_Rs, y_trn, dtype=y_tst.dtype)\n",
    "y_trn_hat = predict(X_trn, all_Rs, y_trn, dtype=y_trn.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n",
      "Precision: 0.5555555555555556\n",
      "Recall: 0.8823529411764706\n",
      "F1: 0.6818181818181819\n",
      "\n",
      "Precision (weighted): 0.7734463276836158\n",
      "Recall (weighted): 0.7\n",
      "F1 (weighted): 0.7036855036855036\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_tst, y_tst_hat)\n",
    "\n",
    "if dataset_name == \"seismic-bumps\":\n",
    "    precision = precision_score(y_tst, y_tst_hat)\n",
    "    recall = recall_score(y_tst, y_tst_hat)\n",
    "    f1 = f1_score(y_tst, y_tst_hat)\n",
    "\n",
    "elif dataset_name == \"breast-cancer-wisconsin\":\n",
    "    precision = precision_score(y_tst, y_tst_hat, pos_label=4)\n",
    "    recall = recall_score(y_tst, y_tst_hat, pos_label=4)\n",
    "    f1 = f1_score(y_tst, y_tst_hat, pos_label=4)\n",
    "\n",
    "else:\n",
    "    precision = precision_score(y_tst, y_tst_hat, average='macro')\n",
    "    recall = recall_score(y_tst, y_tst_hat, average='macro')\n",
    "    f1 = f1_score(y_tst, y_tst_hat, average='macro')\n",
    "    \n",
    "    \n",
    "precision_w = precision_score(y_tst, y_tst_hat, average='weighted')\n",
    "recall_w = recall_score(y_tst, y_tst_hat, average='weighted')\n",
    "f1_w = f1_score(y_tst, y_tst_hat, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {acc}')\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')\n",
    "print()\n",
    "print(f'Precision (weighted): {precision_w}')\n",
    "print(f'Recall (weighted): {recall_w}')\n",
    "print(f'F1 (weighted): {f1_w}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8067978533094812\n",
      "Precision: 0.6375838926174496\n",
      "Recall: 1.0\n",
      "F1: 0.7786885245901639\n",
      "\n",
      "Precision (weighted): 0.8768174232510115\n",
      "Recall (weighted): 0.8067978533094812\n",
      "F1 (weighted): 0.8116165953756499\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_trn, y_trn_hat)\n",
    "\n",
    "if dataset_name == \"seismic-bumps\":\n",
    "    precision = precision_score(y_trn, y_trn_hat)\n",
    "    recall = recall_score(y_trn, y_trn_hat)\n",
    "    f1 = f1_score(y_trn, y_trn_hat)\n",
    "\n",
    "elif dataset_name == \"breast-cancer-wisconsin\":\n",
    "    precision = precision_score(y_trn, y_trn_hat, pos_label=4)\n",
    "    recall = recall_score(y_trn, y_trn_hat, pos_label=4)\n",
    "    f1 = f1_score(y_trn, y_trn_hat, pos_label=4)\n",
    "\n",
    "else:\n",
    "    precision = precision_score(y_trn, y_trn_hat, average='macro')\n",
    "    recall = recall_score(y_trn, y_trn_hat, average='macro')\n",
    "    f1 = f1_score(y_trn, y_trn_hat, average='macro')\n",
    "    \n",
    "precision_w = precision_score(y_trn, y_trn_hat, average='weighted')\n",
    "recall_w = recall_score(y_trn, y_trn_hat, average='weighted')\n",
    "f1_w = f1_score(y_trn, y_trn_hat, average='weighted')    \n",
    "\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')\n",
    "print()\n",
    "print(f'Precision (weighted): {precision_w}')\n",
    "print(f'Recall (weighted): {recall_w}')\n",
    "print(f'F1 (weighted): {f1_w}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66403a1342d2aa7accf4b5905b124973c3be20b2a1242511608c6e5eca88e39b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('mai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
